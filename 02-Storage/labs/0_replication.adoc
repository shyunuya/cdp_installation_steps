=== Generating 500MB teragen file ===
....
[root@ed01 ~]# hadoop jar /opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar teragen -Dmapreduce.job.maps=300 5000000 /user/root/edshin
20/09/29 10:25:05 WARN impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
20/09/29 10:25:05 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
20/09/29 10:25:05 INFO impl.MetricsSystemImpl: JobTracker metrics system started
20/09/29 10:25:06 INFO terasort.TeraGen: Generating 5000000 using 1
20/09/29 10:25:06 INFO mapreduce.JobSubmitter: number of splits:1
20/09/29 10:25:06 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1726881729_0001
20/09/29 10:25:06 INFO mapreduce.JobSubmitter: Executing with tokens: []
20/09/29 10:25:06 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
20/09/29 10:25:06 INFO mapreduce.Job: Running job: job_local1726881729_0001
20/09/29 10:25:06 INFO mapred.LocalJobRunner: OutputCommitter set in config null
20/09/29 10:25:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
20/09/29 10:25:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/09/29 10:25:06 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
20/09/29 10:25:06 INFO mapred.LocalJobRunner: Waiting for map tasks
20/09/29 10:25:06 INFO mapred.LocalJobRunner: Starting task: attempt_local1726881729_0001_m_000000_0
20/09/29 10:25:06 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
20/09/29 10:25:06 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/09/29 10:25:06 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/09/29 10:25:06 INFO mapred.MapTask: Processing split: org.apache.hadoop.examples.terasort.TeraGen$RangeInputFormat$RangeInputSplit@4a73fecd
20/09/29 10:25:07 INFO mapreduce.Job: Job job_local1726881729_0001 running in uber mode : false
20/09/29 10:25:07 INFO mapreduce.Job:  map 0% reduce 0%
20/09/29 10:25:12 INFO mapred.LocalJobRunner:
20/09/29 10:25:13 INFO mapred.Task: Task:attempt_local1726881729_0001_m_000000_0 is done. And is in the process of committing
20/09/29 10:25:13 INFO mapred.LocalJobRunner:
20/09/29 10:25:13 INFO mapred.Task: Task attempt_local1726881729_0001_m_000000_0 is allowed to commit now
20/09/29 10:25:13 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1726881729_0001_m_000000_0' to hdfs://ed02.cloudera.com:8020/user/root/edshin
20/09/29 10:25:13 INFO mapred.LocalJobRunner: map
20/09/29 10:25:13 INFO mapred.Task: Task 'attempt_local1726881729_0001_m_000000_0' done.
20/09/29 10:25:13 INFO mapred.Task: Final Counters for attempt_local1726881729_0001_m_000000_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=334430
		FILE: Number of bytes written=873560
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=0
		HDFS: Number of bytes written=500000000
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=5000000
		Map output records=5000000
		Input split bytes=82
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=69
		Total committed heap usage (bytes)=184025088
	org.apache.hadoop.examples.terasort.TeraGen$Counters
		CHECKSUM=10735710707299981
	File Input Format Counters
		Bytes Read=0
	File Output Format Counters
		Bytes Written=500000000
20/09/29 10:25:13 INFO mapred.LocalJobRunner: Finishing task: attempt_local1726881729_0001_m_000000_0
20/09/29 10:25:13 INFO mapred.LocalJobRunner: map task executor complete.
20/09/29 10:25:13 INFO mapreduce.Job:  map 100% reduce 0%
20/09/29 10:25:13 INFO mapreduce.Job: Job job_local1726881729_0001 completed successfully
20/09/29 10:25:13 INFO mapreduce.Job: Counters: 22
	File System Counters
		FILE: Number of bytes read=334430
		FILE: Number of bytes written=873560
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=0
		HDFS: Number of bytes written=500000000
		HDFS: Number of read operations=5
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=3
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=5000000
		Map output records=5000000
		Input split bytes=82
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=69
		Total committed heap usage (bytes)=184025088
	org.apache.hadoop.examples.terasort.TeraGen$Counters
		CHECKSUM=10735710707299981
	File Input Format Counters
		Bytes Read=0
	File Output Format Counters
		Bytes Written=500000000
....
== Distcp to Alex's cluster
....
[root@ed01 ~]# hadoop distcp /user/root/edshin/* hdfs://ccycloud-2.basecamp-source.root.hwx.site:8020/user/rep_user/student_data/edshin/
20/09/29 10:35:54 INFO tools.DistCp: Input Options: DistCpOptions{atomicCommit=false, syncFolder=false, deleteMissing=false, ignoreFailures=false, overwrite=false, append=false, useDiff=false, useRdiff=false, fromSnapshot=null, toSnapshot=null, skipCRC=false, blocking=true, numListstatusThreads=0, maxMaps=20, mapBandwidth=0.0, copyStrategy='uniformsize', preserveStatus=[BLOCKSIZE], atomicWorkPath=null, logPath=null, sourceFileListing=null, sourcePaths=[/user/root/edshin/*], targetPath=hdfs://ccycloud-2.basecamp-source.root.hwx.site:8020/user/rep_user/student_data/edshin, filtersFile='null', blocksPerChunk=0, copyBufferSize=8192, verboseLog=false, directWrite=false}, sourcePaths=[/user/root/edshin/*], targetPathExists=false, preserveRawXattrsfalse
20/09/29 10:35:54 WARN impl.MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
20/09/29 10:35:54 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
20/09/29 10:35:54 INFO impl.MetricsSystemImpl: JobTracker metrics system started
20/09/29 10:35:54 INFO tools.SimpleCopyListing: Paths (files+dirs) cnt = 2; dirCnt = 0
20/09/29 10:35:54 INFO tools.SimpleCopyListing: Build file listing completed.
20/09/29 10:35:54 INFO Configuration.deprecation: io.sort.mb is deprecated. Instead, use mapreduce.task.io.sort.mb
20/09/29 10:35:54 INFO Configuration.deprecation: io.sort.factor is deprecated. Instead, use mapreduce.task.io.sort.factor
20/09/29 10:35:54 INFO tools.DistCp: Number of paths in the copy list: 2
20/09/29 10:35:54 INFO tools.DistCp: Number of paths in the copy list: 2
20/09/29 10:35:54 WARN impl.MetricsSystemImpl: JobTracker metrics system already initialized!
20/09/29 10:35:54 INFO mapreduce.JobSubmitter: number of splits:1
20/09/29 10:35:54 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1293001322_0001
20/09/29 10:35:54 INFO mapreduce.JobSubmitter: Executing with tokens: []
20/09/29 10:35:54 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
20/09/29 10:35:54 INFO tools.DistCp: DistCp job-id: job_local1293001322_0001
20/09/29 10:35:54 INFO mapreduce.Job: Running job: job_local1293001322_0001
20/09/29 10:35:54 INFO mapred.LocalJobRunner: OutputCommitter set in config null
20/09/29 10:35:54 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
20/09/29 10:35:54 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/09/29 10:35:54 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
20/09/29 10:35:54 INFO mapred.LocalJobRunner: Waiting for map tasks
20/09/29 10:35:54 INFO mapred.LocalJobRunner: Starting task: attempt_local1293001322_0001_m_000000_0
20/09/29 10:35:55 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
20/09/29 10:35:55 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/09/29 10:35:55 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
20/09/29 10:35:55 INFO mapred.MapTask: Processing split: file:/tmp/hadoop/mapred/staging/root564811462/.staging/_distcp-1287027780/fileList.seq:0+410
20/09/29 10:35:55 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2
20/09/29 10:35:55 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
20/09/29 10:35:55 INFO mapred.CopyMapper: Copying hdfs://ed02.cloudera.com:8020/user/root/edshin/part-m-00000 to hdfs://ccycloud-2.basecamp-source.root.hwx.site:8020/user/rep_user/student_data/edshin/part-m-00000
20/09/29 10:35:55 INFO mapred.RetriableFileCopyCommand: Copying hdfs://ed02.cloudera.com:8020/user/root/edshin/part-m-00000 to hdfs://ccycloud-2.basecamp-source.root.hwx.site:8020/user/rep_user/student_data/edshin/part-m-00000
20/09/29 10:35:55 INFO mapred.RetriableFileCopyCommand: Creating temp file: hdfs://ccycloud-2.basecamp-source.root.hwx.site:8020/user/rep_user/student_data/edshin/.distcp.tmp.attempt_local1293001322_0001_m_000000_0
20/09/29 10:35:55 INFO mapred.RetriableFileCopyCommand: Writing to temporary target file path hdfs://ccycloud-2.basecamp-source.root.hwx.site:8020/user/rep_user/student_data/edshin/.distcp.tmp.attempt_local1293001322_0001_m_000000_0
20/09/29 10:35:55 INFO mapreduce.Job: Job job_local1293001322_0001 running in uber mode : false
20/09/29 10:35:55 INFO mapreduce.Job:  map 0% reduce 0%
20/09/29 10:36:00 INFO mapred.RetriableFileCopyCommand: Renaming temporary target file path hdfs://ccycloud-2.basecamp-source.root.hwx.site:8020/user/rep_user/student_data/edshin/.distcp.tmp.attempt_local1293001322_0001_m_000000_0 to hdfs://ccycloud-2.basecamp-source.root.hwx.site:8020/user/rep_user/student_data/edshin/part-m-00000
20/09/29 10:36:00 INFO mapred.RetriableFileCopyCommand: Completed writing hdfs://ccycloud-2.basecamp-source.root.hwx.site:8020/user/rep_user/student_data/edshin/part-m-00000 (500000000 bytes)
20/09/29 10:36:00 INFO mapred.CopyMapper: Copying hdfs://ed02.cloudera.com:8020/user/root/edshin/_SUCCESS to hdfs://ccycloud-2.basecamp-source.root.hwx.site:8020/user/rep_user/student_data/edshin/_SUCCESS
20/09/29 10:36:00 INFO mapred.RetriableFileCopyCommand: Copying hdfs://ed02.cloudera.com:8020/user/root/edshin/_SUCCESS to hdfs://ccycloud-2.basecamp-source.root.hwx.site:8020/user/rep_user/student_data/edshin/_SUCCESS
20/09/29 10:36:00 INFO mapred.RetriableFileCopyCommand: Creating temp file: hdfs://ccycloud-2.basecamp-source.root.hwx.site:8020/user/rep_user/student_data/edshin/.distcp.tmp.attempt_local1293001322_0001_m_000000_0
20/09/29 10:36:00 INFO mapred.RetriableFileCopyCommand: Writing to temporary target file path hdfs://ccycloud-2.basecamp-source.root.hwx.site:8020/user/rep_user/student_data/edshin/.distcp.tmp.attempt_local1293001322_0001_m_000000_0
20/09/29 10:36:00 INFO mapred.RetriableFileCopyCommand: Renaming temporary target file path hdfs://ccycloud-2.basecamp-source.root.hwx.site:8020/user/rep_user/student_data/edshin/.distcp.tmp.attempt_local1293001322_0001_m_000000_0 to hdfs://ccycloud-2.basecamp-source.root.hwx.site:8020/user/rep_user/student_data/edshin/_SUCCESS
20/09/29 10:36:00 INFO mapred.RetriableFileCopyCommand: Completed writing hdfs://ccycloud-2.basecamp-source.root.hwx.site:8020/user/rep_user/student_data/edshin/_SUCCESS (0 bytes)
20/09/29 10:36:00 INFO mapred.LocalJobRunner:
20/09/29 10:36:00 INFO mapred.Task: Task:attempt_local1293001322_0001_m_000000_0 is done. And is in the process of committing
20/09/29 10:36:00 INFO mapred.LocalJobRunner:
20/09/29 10:36:00 INFO mapred.Task: Task attempt_local1293001322_0001_m_000000_0 is allowed to commit now
20/09/29 10:36:00 INFO output.FileOutputCommitter: Saved output of task 'attempt_local1293001322_0001_m_000000_0' to file:/tmp/hadoop/mapred/staging/root564811462/.staging/_distcp-1287027780/_logs
20/09/29 10:36:00 INFO mapred.LocalJobRunner: Copying hdfs://ed02.cloudera.com:8020/user/root/edshin/_SUCCESS to hdfs://ccycloud-2.basecamp-source.root.hwx.site:8020/user/rep_user/student_data/edshin/_SUCCESS
20/09/29 10:36:00 INFO mapred.Task: Task 'attempt_local1293001322_0001_m_000000_0' done.
20/09/29 10:36:00 INFO mapred.Task: Final Counters for attempt_local1293001322_0001_m_000000_0: Counters: 25
	File System Counters
		FILE: Number of bytes read=205903
		FILE: Number of bytes written=752383
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=500000000
		HDFS: Number of bytes written=500000000
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=2
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=42
		Total committed heap usage (bytes)=180879360
	File Input Format Counters
		Bytes Read=442
	File Output Format Counters
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=100000000
		Bytes Copied=500000000
		Bytes Expected=500000000
		Files Copied=2
20/09/29 10:36:00 INFO mapred.LocalJobRunner: Finishing task: attempt_local1293001322_0001_m_000000_0
20/09/29 10:36:00 INFO mapred.LocalJobRunner: map task executor complete.
20/09/29 10:36:00 INFO mapred.CopyCommitter: About to preserve attributes: B
20/09/29 10:36:00 INFO mapred.CopyCommitter: Preserved status on 0 dir entries on target
20/09/29 10:36:00 INFO mapred.CopyCommitter: Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/root564811462/.staging/_distcp-1287027780
20/09/29 10:36:00 INFO mapreduce.Job:  map 100% reduce 0%
20/09/29 10:36:00 INFO mapreduce.Job: Job job_local1293001322_0001 completed successfully
20/09/29 10:36:00 INFO mapreduce.Job: Counters: 25
	File System Counters
		FILE: Number of bytes read=205903
		FILE: Number of bytes written=752383
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=500000000
		HDFS: Number of bytes written=500000000
		HDFS: Number of read operations=24
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=6
		HDFS: Number of bytes read erasure-coded=0
	Map-Reduce Framework
		Map input records=2
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=42
		Total committed heap usage (bytes)=180879360
	File Input Format Counters
		Bytes Read=442
	File Output Format Counters
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=100000000
		Bytes Copied=500000000
		Bytes Expected=500000000
		Files Copied=2
....
=== fsck from my local cluster
....
[root@ed01 ~]# hdfs fsck /user/root/edshin -files -blocks
Connecting to namenode via http://ed02.cloudera.com:9870/fsck?ugi=root&files=1&blocks=1&path=%2Fuser%2Froot%2Fedshin
FSCK started by root (auth:SIMPLE) from /172.27.136.7 for path /user/root/edshin at Tue Sep 29 10:38:04 PDT 2020

/user/root/edshin <dir>
/user/root/edshin/_SUCCESS 0 bytes, replicated: replication=3, 0 block(s):  OK

/user/root/edshin/part-m-00000 500000000 bytes, replicated: replication=3, 4 block(s):  OK
0. BP-2004681499-172.27.111.198-1601390584873:blk_1073743687_2863 len=134217728 Live_repl=3
1. BP-2004681499-172.27.111.198-1601390584873:blk_1073743688_2864 len=134217728 Live_repl=3
2. BP-2004681499-172.27.111.198-1601390584873:blk_1073743689_2865 len=134217728 Live_repl=3
3. BP-2004681499-172.27.111.198-1601390584873:blk_1073743690_2866 len=97346816 Live_repl=3


Status: HEALTHY
 Number of data-nodes:	3
 Number of racks:		1
 Total dirs:			1
 Total symlinks:		0

Replicated Blocks:
 Total size:	500000000 B
 Total files:	2
 Total blocks (validated):	4 (avg. block size 125000000 B)
 Minimally replicated blocks:	4 (100.0 %)
 Over-replicated blocks:	0 (0.0 %)
 Under-replicated blocks:	0 (0.0 %)
 Mis-replicated blocks:		0 (0.0 %)
 Default replication factor:	3
 Average block replication:	3.0
 Missing blocks:		0
 Corrupt blocks:		0
 Missing replicas:		0 (0.0 %)
 Blocks queued for replication:	0

Erasure Coded Block Groups:
 Total size:	0 B
 Total files:	0
 Total block groups (validated):	0
 Minimally erasure-coded block groups:	0
 Over-erasure-coded block groups:	0
 Under-erasure-coded block groups:	0
 Unsatisfactory placement block groups:	0
 Average block group size:	0.0
 Missing block groups:		0
 Corrupt block groups:		0
 Missing internal blocks:	0
 Blocks queued for replication:	0
FSCK ended at Tue Sep 29 10:38:04 PDT 2020 in 3 milliseconds


The filesystem under path '/user/root/edshin' is HEALTHY
....

=== fsck from Alex's cluster
....
[root@ccycloud-2 ~]# hdfs fsck /user/rep_user/student_data/edshin/ -files -blocks
Connecting to namenode via http://ccycloud-2.basecamp-source.root.hwx.site:9870/fsck?ugi=root&files=1&blocks=1&path=%2Fuser%2Frep_user%2Fstudent_data%2Fedshin
FSCK started by root (auth:SIMPLE) from /172.27.129.198 for path /user/rep_user/student_data/edshin at Tue Sep 29 10:47:04 PDT 2020

/user/rep_user/student_data/edshin <dir>
/user/rep_user/student_data/edshin/_SUCCESS 0 bytes, replicated: replication=3, 0 block(s):  OK

/user/rep_user/student_data/edshin/part-m-00000 500000000 bytes, replicated: replication=3, 4 block(s):  OK
0. BP-55971505-172.27.129.198-1601305423414:blk_1073744617_3793 len=134217728 Live_repl=3
1. BP-55971505-172.27.129.198-1601305423414:blk_1073744618_3794 len=134217728 Live_repl=3
2. BP-55971505-172.27.129.198-1601305423414:blk_1073744619_3795 len=134217728 Live_repl=3
3. BP-55971505-172.27.129.198-1601305423414:blk_1073744620_3796 len=97346816 Live_repl=3


Status: HEALTHY
 Number of data-nodes:	3
 Number of racks:		1
 Total dirs:			1
 Total symlinks:		0

Replicated Blocks:
 Total size:	500000000 B
 Total files:	2
 Total blocks (validated):	4 (avg. block size 125000000 B)
 Minimally replicated blocks:	4 (100.0 %)
 Over-replicated blocks:	0 (0.0 %)
 Under-replicated blocks:	0 (0.0 %)
 Mis-replicated blocks:		0 (0.0 %)
 Default replication factor:	3
 Average block replication:	3.0
 Missing blocks:		0
 Corrupt blocks:		0
 Missing replicas:		0 (0.0 %)
 Blocks queued for replication:	0

Erasure Coded Block Groups:
 Total size:	0 B
 Total files:	0
 Total block groups (validated):	0
 Minimally erasure-coded block groups:	0
 Over-erasure-coded block groups:	0
 Under-erasure-coded block groups:	0
 Unsatisfactory placement block groups:	0
 Average block group size:	0.0
 Missing block groups:		0
 Corrupt block groups:		0
 Missing internal blocks:	0
 Blocks queued for replication:	0
FSCK ended at Tue Sep 29 10:47:04 PDT 2020 in 3 milliseconds


The filesystem under path '/user/rep_user/student_data/edshin' is HEALTHY